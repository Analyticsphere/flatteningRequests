---
title: "Generate Query from Source Table Schema & Merge w/ Manaul Query"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 80
---

#### 0. Load dependencies and define parameters

```{r, setup}
library(jsonlite)
library(tools)
library(reticulate)
library(bigrquery)
library(dplyr)
library(glue)
source("gcp_query_tools/connect_analytics_helper_functions.R") # Load helper functions

# GCP Project IDs
projects <- list(dev  = "nih-nci-dceg-connect-dev", 
                 stg  = "nih-nci-dceg-connect-stg-5519", 
                 prod = "nih-nci-dceg-connect-prod-6d04")
# BQ Source Tables
tables   <- list(
  b    = "Connect.biospecimen",          bs      = "Connect.bioSurvey_v1", 
  cbs  = "Connect.clinicalBioSurvey_v1", ms      = "Connect.menstrualSurvey_v1",
  m1v1 = "Connect.module1_v1",           m1v2    = "Connect.module1_v2",
  m2v1 = "Connect.module2_v1",           m2v2    = "Connect.module2_v2",
  m3   = "Connect.module3_v1",           m4      = "Connect.module4_v1",
  p    = "Connect.participants",         cs19    = "Connect.covid19Survey_v1",
  n    = "Connect.notifications",        k       = "Connect.kitAssembly",
  mw   = "Connect.mouthwash_v1",         co      = "Connect.cancerOccurrence")

########### DEFINE PARAMETERS ##################################################
tiers_to_update    <- 'prod' # GCP tiers to update sch. queries for
table              <- tables$co # table to be flattened (can only select one)
run_now            <- TRUE # Set to true if you want to both sch. and run query
################################################################################

# Authenticate to BigQuery
project            <- projects[[tiers_to_update]] # project to get schema from (can only select one)
bigrquery::bq_auth()

# Generate file names given table name
module        <- strsplit(table, split=".", fixed=TRUE)[[1]][2]
query_folder  <- paste0("queryGenerators/FlatConnect_queries/")
module_folder <- paste0(query_folder, module,"/",tiers_to_update,"/")
query_config  <- jsonlite::fromJSON(paste0(module_folder,"query-config.json"))
query_config

# Create temporary directory to store temp files in
tmp_folder    <- paste0(module_folder,"tmp/")
if (!dir.exists(tmp_folder)) {dir.create(tmp_folder)}
```

#### 1. Get schema from BQ as a JSON (only format option)

```{r}
# Name schema files
schema_json  <- paste0(tmp_folder,module,"-schema.json")
schema_csv   <- paste0(tmp_folder,module,"-schema.csv")

# Split the string using "."
split_string <- strsplit(table, ".", fixed = TRUE)
dataset_id   <- split_string[[1]][1]
table_id     <- split_string[[1]][2]

# Construct bq_table object
bq_table     <- bq_table(project, dataset_id, table_id)

# Retrive the metadata for the table (a list containing the schema)
metadata     <- bigrquery::bq_table_meta(bq_table)

# Simplify the structure of the schema so that it matches that returned by bq CLI
schema       <- metadata$schema$fields

# Write the schema to a JSON string
schema_as_json <- jsonlite::toJSON(schema, pretty = TRUE, auto_unbox = TRUE)
write(schema_as_json, schema_json)
```

#### 2. Convert schema from JSON to CSV

```{r}
# Filter some names and types from csv and export to csv. Return a dataframe.
names_to_filter <- c("__key__", "__error__", "__has_error__",
                     "treeJSON", "allEmails", "allPhoneNo", 
                     "query", "unverifiedSeen", "undefined", 
                     "utm_id", "utm_source", "verifiedSeen", 
                     "firstSurveyCompletedSeen", "COMPLETED", 
                     "COMPLETED_TS", "sha")
types_to_filter <- c("RECORD")
source("gcp_query_tools/json_schema_to_csv.R")
schema_df <- json_schema_to_csv(schema_json, schema_csv, names_to_filter, types_to_filter)
head(schema_df)
```

#### 3. Filter variables into "lists" and "variables" files based on data structure

Variables in the schema are filtered into 2 groups and sends them to different
file formats that can be used by the query generator: (1) variables with JSON
arrays (aka lists) --\> tmp/*-lists-from-schema.json (2) variables with single
values --\> tmp/*-variables-from-schema.csv

Note that only leaf variables are considered.

```{r}
# Generate the query from the schema in the form of a set of variables.csv and lists.json files.
out_json <- paste0(tmp_folder, module, "-lists-from-schema.json")
out_csv  <- paste0(tmp_folder, module, "-variables-from-schema.csv")

# Get variables and lists files from schema
filter_vars_from_schema(project,table,schema_csv,out_csv,out_json)
```

#### 4. Combine json and csv files prior to generating query

Now that we have a new query in the form of variables.csv and lists.json files,
we need to combine the new json file with the old json file. This is useful
because it allows variables from the original files to remain even if they are
not present in the BQ tables yet. It also allows manual changes to be preserved.

```{r}
# -lists.json file from parent folder
old_lists_json <- paste0(module_folder, module, "-lists.json"); old_lists_json

# name combined json file
union_lists_json <- paste0(tmp_folder, module, "-lists-union.json"); union_lists_json

# Get union of old_lists_json and out_json
union_json_str <- get_union_of_json_arrays(old_lists_json, out_json, union_lists_json)
union_json_str
```

We also need to combine the variables.csv file that was generated from the
schema with the original, manually generated variables.csv file. This code will
exclude any duplicates.

```{r}
# Get union of variable files 
old_vars_csv        <- paste0(module_folder, module, "-variables.csv")
union_vars_csv      <- paste0(tmp_folder, module, "-vars-union.csv"); union_vars_csv
union_var_chr_array <- get_union_of_variable_csv(old_vars_csv, out_csv, union_vars_csv)
```

#### 5. Deal with exceptions

Some of the variables that contain JSON arrays in BQ only have single values in
the array. So we can exclude them from the "lists.json" file and put them in the
"variables.csv" instead. So a variable that appears as "d_CID: [178420302]" will
not be flattened as "d_cid_d_178420302" and have a value of 1. It will instead
be flatted as d_cid and will return a value of [178420302]. I added this
exception process to accommodate some issues Kelsey was having with variables
from Quest with unexpected data structure. We're ignoring the CID: d_742186726
which identifies stray tubes.

```{r}
# Define exceptions
exceptions <- c(178420302, 958239616, 353358909, 104430631, 742186726, 496539718)

# Get a list of variables with arrays containing "exception CID"
vars_w_exceptions <- get_vars_with_specified_vals(union_lists_json, 
                                                  exceptions, 
                                                  max_array_len = 2) 
vars_w_exceptions

# Remove list of variables with exceptions from the data set
new_lists_json    <- paste0(tmp_folder, module, "-lists-union-mod.json")
updated_variables <- remove_vars_from_json(union_lists_json, 
                                           vars_w_exceptions,
                                           output_filename = new_lists_json) 

# Add list of variables with exceptions to \*-variables\*.csv
new_vars_csv      <- paste0(tmp_folder, module, "-variables-union-mod.csv")
add_novel_vars_to_csv(vars_w_exceptions, union_vars_csv, out_file = new_vars_csv)
```

Get list of variables from csv file that are of type RECORD or mode REPEATED in
the schema. There shouldn't be any left at this point, but just in case...

```{r}
#TODO This chunk needs to be tested.
vars_to_remove <- get_record_and_repeated_vars(project, table, schema_csv, new_vars_csv)
vars_to_remove

# Remove these variables from the new csv file
if ( length(vars_to_remove ) != 0) { remove_vars_from_csv(new_vars_csv, vars_to_remove) }
```

#### 6. Replace original lists.json and variables.csv files in the parent directory

```{r}
# Replace original files in parent directory with new ones
file.rename(new_vars_csv,   old_vars_csv)
file.rename(new_lists_json, old_lists_json)
```

#### 7. Clean up intermediate files from tmp folder

They don't need to be saved or version controlled so might as well avoid
clutter.

```{r}
# Delete intermediate files from tmp folder. 
unlink(tmp_folder, recursive=TRUE)
```

#### 8. Generate query

```{r}
## Warren's query generator
# working_dir     <- getwd()
# query_generator <- paste0(module, "-query_generator.js")
# Sys.setenv(MODULE_FOLDER   = module_folder,
#            QUERY_GENERATOR = query_generator,
#            WORKNG_DIR      = working_dir)
# 
# # Using shell commands, go to the module folder, run the query generator (node.js),
# # and return to the working directory.
# system("cd ${MODULE_FOLDER} && node ${QUERY_GENERATOR}; cd ${WORKING_DIR}")

# TODO Add option to take query_config as variable
source('gcp_query_tools/generate_flattening_query.R')
for (tier in tiers_to_update){
  print(tier)
    query <- 
      generate_flattening_query(
        source_table      = query_config$data_source[tier],
        destination_table = glue("{project}.{query_config$output_table}"),
        variable_csv      = old_vars_csv,
        arrays_json       = old_lists_json,
        table_description = query_config$table_description,
        filter_statement  = query_config$filter_statement,
        var_prefix        = query_config$variable_prefix,
        order_statement   = query_config$order_statement)
    query_file_path <- paste0(module_folder,query_config$output_table,"-",tier,".sql") %>%                           print()
    fileConn <- file(query_file_path)
    writeLines(query, fileConn)
    close(fileConn)
}

```

#### 9. Update scheduled queries in GCP programatically

```{r}
# Note: If you get this error...
#           "Handshake failed with fatal error SSL_ERROR_SSL: 
#            error:1000007d:SSL routines:OPENSSL_internal:CERTIFICATE_VERIFY_FAILED"
#       ...disconnect from the VPN and try again. It seems like NIH blocks this.
source("gcp_query_tools/get_resource_name_of_bq_sch_query.R")
py_func <- 'gcp_query_tools/update_gcp_scheduled_query_b.py'
Sys.setenv(PY_FUNC = py_func, MODULE_FOLDER = module_folder, RUN_NOW = run_now)

# system("gcloud auth login") # Use this to authenticate if needed
for (tier in tiers_to_update){
  resource_name <- query_config$resource_name[tier]
  project_id    <- projects[tier]
  # Make sure the resource_name from the query_config is correct
  if (resource_name != get_resource_name_of_bq_sch_query(project_id, query_config$query_name))      {stop("Resource_name in query_config.json is wrong!")}
  
  Sys.setenv(PROJECT_ID = project_id)
  system('python3 $PY_FUNC $PROJECT_ID $MODULE_FOLDER $RUN_NOW')
}
```
